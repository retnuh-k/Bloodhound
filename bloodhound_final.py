# -*- coding: utf-8 -*-
"""Bloodhound_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F8mX9EzZoSRYDdkyBJJEhngCshYDkfW9

# Load Data, Exploratory Analysis
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import re

try:
    import google.colab
    # Running on Google Colab, so install Biopython first
    !pip install biopython
except ImportError:
    pass

import os
import sys

from urllib.request import urlretrieve

import Bio
from Bio import SeqIO, SearchIO, Entrez
from Bio.Seq import Seq
from Bio.SeqUtils import GC
from Bio.Blast import NCBIWWW
from Bio.Data import CodonTable

print("Python version:", sys.version_info)
print("Biopython version:", Bio.__version__)

ACA1 = list("MRFPGVKTPDASNHDPDPRYLRGLLKKAGISQRRAAELLGLSDRVMRYYLSEDIKEGYRPAPYTVQFALECLANDPPSA")

#ACA2 = list("MTHYELQALRKLLMLEVSEAAREIGDVSPRSWQYWESGRSPVPDDVANQIRNLTDMRYQLLELRTEQIEKAGKPIQLNFYRTLDDYEAVTGKRDVVSWRLTQAVAATLFAEGDVTLVEQGGLTLE")
ACA2 = list("MTNKELQAIRKLLMLDVSEAAEHIGRVSARSWQYWESGRSAVPDDVEQEMLDLASVRIEMMSAIDKRLADGERPKLRFYNKLDEYLADNPDHNVIGWRLSQSVAALYYTEGHADLI")

ACA3 = list("MKKFEAPEIGYTPANLKALRKQFGLTQAQVAEITGTKTGYSVRRWEAAIDAKNRADMPLVKWQKLLDSLK")
ACA4 = list("MTEEQFSALAELMRLRGGPGEDAARLVLVNGLKPTDAARKTGITPQAVNKTLSSCRRGIELAKRVFT")
ACA5 = list("MSLTEYIDKNFAGNKAAFARHMGVDAQAVNKWIKSEWFVSTTDDNKIYLSSVRREIPPVA")
ACA6 = list("MTAMKEWRARMGWSQRRAAQELGVTLPTYQSWEKGIRLSDGSPIDPPLTALLAAAAREKGLPPIS")
ACA7 = list("MIDARKHYDPNLAPELVRRALAVTGTQKELAERLDVSRTYLQLLGKGQKSMSYAVQVMLEQVIQDGET")
ACA8 = list("")
ACA9 = list("MKRQVRVGNTIYYVESEDDLVSVTHELARQGIKIEKIAYLLGVSVRKVRQYLESC")
ACA10 = list("MSSATPDPAEILTARKAVGLSQTAAAALVHSSLRTWQQWEAGDRRMHPGLWELFLLKTQLPSPSS")
ACA11 = list("MKVDTKQIEWLLKNASGYQISKMSGVAQPTISALINKKRSIENLTIETGHKLTELANQMQKTP")
ACA12 = list("MLINTSRVEMVLMNKAISAYRLAKEIGIQESSISLLRNGKKDLDKLSLEVAMRVQAWIDAGNYSFSYDYSELIEKLEADIEKGLADEYIYIVRGGYNEVMEKCMIIDYYYDPEEIAEGDIAEKVLTSSALAEMEKDNEIF")
ACA13 = list("MTDELTARQRADKKWNEKNREHRNYMTKRSTARGFIRNHATKEDLLELQKLIQENLKKF")

properties = {
    'G': 1,
    'A': 1,
    'V': 1,
    'L': 1,
    'I': 1,
    'M': 1,
    'F': 1,
    'W': 1,
    'P': 1,
    'S': 2,
    'T': 2,
    'C': 2,
    'Y': 2,
    'N': 2,
    'Q': 2,
    'D': 3,
    'E': 3,
    'K': 4,
    'R': 4,
    'H': 4,
    }

fine_properties = {
    'G': 0,
    'A': 5,
    'V': 5,
    'L': 5,
    'I': 5,
    'M': 0,
    'F': 4,
    'W': 4,
    'P': 0,
    'S': 1,
    'T': 1,
    'C': 0,
    'Y': 1,
    'N': 1,
    'Q': 1,
    'D': 2,
    'E': 2,
    'K': 3,
    'R': 3,
    'H': 3,
    } 
nonpolar = "GGGGGCGGTGGAATGCCTCCACCGCCCTGTTGC"
polar = "TCTTCGTCATCCACAACTACGACCTATTACAATAACCAACAG"
acidic = "GATGACGAAGAG"
basic = "AAAAAGAAGAAACATCAC"
aromatic = "TTTTTCTGG"
aliphatic = "GCGGCTGCAGCCGTTGTGGTCGTATTATTGCTTCTGCTACTC"
plotColors_fine = {0: "black", 1: "green", 2: "red", 3: "blue", 4: "cyan", 5: "gold"}
# 0: nonpolar
# 1: polar
# 2: acidic
# 3: basic
# 4: aromatic
# 5: aliphatic

"""##Helper Methods"""

def toProperties(sequence):
  propSeq = []
  for x in sequence:
    propSeq.append(fine_properties.get(x))  
    
  return propSeq

def getStartingProbs(state_seq, states):
  starting_prob = {}
  for s in states:
    starting_prob[s] = state_seq.count(s)/len(state_seq)
  return starting_prob

def toColors(propSeq):
  colorSeq = []
  for x in propSeq:
    colorSeq.append(plotColors_fine.get(x))
  
  return colorSeq

#create polarity state adjacency list  
def adjList(stateList):
  adj = {}
  
  for i in range (0,6):
    counts = np.array([0,0,0,0,0,0])
    
    for j in range(len(stateList)-1):
      if stateList[j] == i:
        if stateList[j+1] == 0:
          counts[0] += 1
        elif stateList[j+1] == 1:
          counts[1] += 1
        elif stateList[j+1] == 2:
          counts[2] += 1
        elif stateList[j+1] == 3:
          counts[3] += 1
        elif stateList[j+1] == 4:
          counts[4] += 1
        elif stateList[j+1] == 5:
          counts[5] += 1
    adj[i] = counts
  #print(adj)
  return adj

#use adjacency list to calculate transition probabilities 
def adj_trans(adj):
  transmat = np.eye(6)
  for i in adj.keys():
    if sum(adj[i]) != 0:
      transmat[i-1] = adj[i]/sum(adj[i])
    else:
       transmat[i-1] = adj[i]  
  return transmat

"""##Emission"""

def get_emit(nt, state):
  
  return state.count(nt)/len(state)

nts = {'C', 'T', 'G', 'A'}
states = {"nonpolar":"GGGGGCGGTGGAATGCCTCCACCGCCCTGTTGC", "polar":"TCTTCGTCATCCACAACTACGACCTATTACAATAACCAACAG", "acidic":"GATGACGAAGAG", "basic":"AAAAAGAAGAAACATCAC", "aromatic":"TTTTTCTGG", "aliphatic":"GCGGCTGCAGCCGTTGTGGTCGTATTATTGCTTCTGCTACTC"}

aas ={'G','A', 'V','L','I','M','F','W','P','S','T','C','Y','N','Q','D', 'E','K','R','H'}
pep_states = {"nonpolar": "GMPC", "polar":"STYNQ", "acidic": "DQ", "basic":"RKH", "aromatic":"FW", "aliphatic":"AVLI"}
emat = []



for state in pep_states.keys():
  
  stateList = []
  for j in aas:
    
    stateList.append(get_emit(j, pep_states[state]))
    
  emat.append(stateList)
  
 
emat = np.asarray(emat)  
emissiondf = pd.DataFrame(emat, columns = ['Y','E', 'M', 'P','G','S','W','D','A','C','N','L','I','V','Q','T','K', 'H','R','F'])
emissiondf

"""##Create Transition Matrices for each Aca Gene"""

# Transition matrices 
ACA1tm = adj_trans(adjList(toProperties(ACA1)))
ACA2tm = adj_trans(adjList(toProperties(ACA2)))
ACA3tm = adj_trans(adjList(toProperties(ACA3)))
ACA4tm = adj_trans(adjList(toProperties(ACA4)))
ACA5tm = adj_trans(adjList(toProperties(ACA5)))
ACA6tm = adj_trans(adjList(toProperties(ACA6)))
ACA7tm = adj_trans(adjList(toProperties(ACA7)))
ACA9tm = adj_trans(adjList(toProperties(ACA9)))
ACA10tm = adj_trans(adjList(toProperties(ACA10)))
ACA11tm = adj_trans(adjList(toProperties(ACA11)))
ACA12tm = adj_trans(adjList(toProperties(ACA12)))
ACA13tm = adj_trans(adjList(toProperties(ACA13)))

"""#Single ACA HMM: Predict most likely AA sequence

## Viterbi Algorithm
"""

def viterbi(observations, states, start_p, trans_p, emit_p):

    V = [{}]
    for st in states:
      if emit_p.iloc[st][observations[0]] != 0:
        V[0][st] = {"prob": np.log(start_p[st]) + np.log(emit_p.iloc[st][observations[0]]), "prev": None}
      else:  V[0][st] = {"prob": np.log(start_p[st]), "prev": None}


    for t in range(1, len(observations)):
        V.append({})
        for st in states:
          if trans_p[states[0]][st] != 0:
            max_tr_prob = V[t - 1][states[0]]["prob"] + np.log(trans_p[states[0]][st])
          else:
            max_tr_prob = V[t - 1][states[0]]["prob"]
          prev_st_selected = states[0]
          for prev_st in states[1:]:
            if trans_p[prev_st][st] != 0:
              tr_prob = V[t - 1][prev_st]["prob"] + np.log(trans_p[prev_st][st])
            else: 
              tr_prob = V[t - 1][prev_st]["prob"]
            if tr_prob > max_tr_prob:
                   max_tr_prob = tr_prob
                   prev_st_selected = prev_st
          if emit_p.iloc[st][observations[t]] != 0:
             max_prob = max_tr_prob + np.log( emit_p.iloc[st][observations[t]])
          else:
             max_prob = max_tr_prob 
  
          V[t][st] = {"prob": max_prob, "prev": prev_st_selected}

    for line in dptable(V):
        print(line)

    max_prob = float('-inf')
    best_st = None
    opt = []
    for st, data in V[-1].items():
      if data["prob"] > max_prob:
        max_prob = data["prob"]
        best_st = st
      opt.append(best_st)
      
      previous = best_st

    for t in range(len(V) - 2, -1, -1):
      
      opt.insert(0, V[t + 1][previous]["prev"])
      previous = V[t + 1][previous]["prev"]
    
    print ("The steps of states are " + str(opt) + " with highest probability of %s" % max_prob)
    return opt
def dptable(V):
    yield " ".join(("%12d" % i) for i in range(len(V)))
    for state in V[0]:
        yield "%.7s: " % str(state) + " ".join("%.7s" % ("%f" % v[state]["prob"]) for v in V)

#aca1 virterbi parameters 
states = [0,1,2,3,4,5]
#print(toProperties(ACA1))
aca2sp = getStartingProbs(toProperties(ACA2), states)

observations = "MTNKELQAIRKLLMLDVSEAAEHIGRVSARSWQYWESGRSAVPDDVEQEMLDLASVRIEMMSAIDKRLADGERPKLRFYNKLDEYLADNPDHNVIGWRLSQSVAALYYTEGHADLI"
obsPep = str(Seq(observations))

states = [0, 1, 2, 3, 4, 5]

start_p = aca2sp

emit_p = emissiondf


trans_p = ACA2tm

decodedStates = viterbi(obsPep, states, start_p, trans_p, emit_p)

ACA2decoded = toColors(decodedStates)
ACA2c = toColors(toProperties(ACA2))

plt.scatter(np.linspace(0, 10, num = len(ACA2c)), [1]*len(ACA2c), c=ACA2c, s=20)
plt.scatter(np.linspace(0, 10, num = len(ACA2decoded)), [2]*len(ACA2decoded), c=ACA2decoded,s=20)

"""# Genomic Superstates

## Pr(coding|genome)
"""

from google.colab import drive
drive.mount('/content/drive')

#Preprocessed genBank file to include only genomic coordinates as strings. GenBank file generated using Prodigal
paeruginosa_gbk = pd.read_csv("/content/drive/MyDrive/Fourth Year/Second Sem/Cg/Project/geneCoords.csv")


pargLength = 6264404


def pr_coding(cleaned_geneCoordsFile, genomeLength):
    geneCoords = []
    geneLengths = []

    for i in range(cleaned_geneCoordsFile.shape[0]-1):
        txt = cleaned_geneCoordsFile.iloc[i, 0]
        a = [int(s) for s in re.findall(r'\b\d+\b', txt)]
        geneCoords.append(list(a))
        geneLengths.append(a[1]-a[0])

    return sum(geneLengths)/genomeLength, geneCoords, geneLengths

prCoding, geneCoords, geneLengths = pr_coding(paeruginosa_gbk, pargLength)
print(prCoding)
#plotting the gene lengths of P. aeuriginosa
plt.hist(geneLengths, bins = 1000)
plt.show()

print("mean gene length: ", np.mean(geneLengths))

#Intergenic Lengths
intergenicLengths = []
for i in range(len(geneCoords)-1):
  
  diff = geneCoords[i+1][0]-geneCoords[i][1]
  if diff < 0:
    intergenicLengths.append(0)
  else:
    intergenicLengths.append(diff)

print(np.mean(intergenicLengths))
plt.hist(intergenicLengths, bins = 1000)
plt.show()

"""# **Test Run:** Random sequence from P. Aeruginosa genome"""

rand_nt_seq="GAGGAAGGTCCCGGCTCGCTGAACTTCAGCATTGCCCAGAGCAAGCTGCGTCGCCTGATCGACCGCACCAGCTTCGCCATGGCCCAGCAGGACGTGCGTTACTACCTCAACGGCATGCTGCTGGAAGTGAACGGCGGCACCCTGCGCTCCGTCGCCACCGACGGCCACCGACTGGCCATGTGCTCGCTGGATGCGCAGATCCCGTCGCAGGACCGCCACCAGGTGATCGTGCCGCGCAAAGGCATCCTCGAACTGGCTCGTCTGCTCACCGAGCAGGACGGCGAAGTCGGCATCGTCCTGGGCCAGCACCATATCCGTGCCACCACTGGCGAATTCACCTTCACTTCGAAGCTGGTGGACGGCAAGTTCCCGGACTACGAGCGTGTACTGCCGCGCGGTGGCGACAAGCTGGTGGTCGGTGACCGCCAGCAACTGCGCGAAGCCTTCAGCCGTACCGCGATCCTCTCCAACGAGAAGTACCGCGGCATTCGCCTGCAGCTTTCCAACGGTTTGCTGAAAATCCAGGCGAACAACCCGGAGCAGGAAGAGGCCGAGGAAGAAGTGCAGGTCGAGTACAACGGCGGCAACCTGGAGATAGGCTTCAACGTCAGTTACCTGCTCGACGTGCTGGGTGTGATCGGTACCGAGCAGGTCCGCTTCATCCTTTCCGATTCCAACAGCAGCGCCCTGGTCCACGAGGCCGACAATGACGATTCTGCCTATGTCGTCATGCCGATGCGCCTCTAAACATACTGAATGTCCCTGACCCGCGTTTCGGTCACCGCGGTGCGCAACCTGCACCCGGTGACCCTCTCCCCCTCCCCCCGCATCAACATCCTCTACGGCGACAACGGCAGCGGCAAGACCAGCGTGCTCGAAGCCATCCACCTGCTGGGCCTGGCGCGTTCATTCCGCAGTGCGCGCTTGCAGCCGGTGATCCAGTATGAGGAAGCGGCCTGCACCGTATTCGGCCAGGTGATGTTGGCCAACGGCATCGCCAGCAACCTGGGGATTTCCCGTGAGCGCCAGGGCGAGTTCACCATCCGCATCGATGGGCAGA"

#Pass seq through GeneMark.HMM --> peptide seq
#http://exon.gatech.edu/GeneMark/gmhmmp.cgi

"""## Coding/Noncoding HMM"""

pi = [1-prCoding, prCoding]

T = np.asarray([[1-1/np.mean(geneLengths),1/np.mean(geneLengths)],[1/np.mean(intergenicLengths),1-1/np.mean(intergenicLengths)]])

#Turn nt into AA
rand_nt_seq_cut = rand_nt_seq[:-(len(rand_nt_seq)%3)]
randseq = Seq(rand_nt_seq_cut)
obsPep = randseq.translate()
print(obsPep)

#jpred link
#http://www.compbio.dundee.ac.uk/jpred4/index_up.html

"""# Secondary structure HMMs for acas

# New Section
"""

# NOTE: aca1 and aca2 have known secondary structures, the rest were predicted with jpred
aca1struct = np.array(list("----------HHH----HHHHHHHHHHH---HHHHHHHH---HHHHHHHH------------HHHHHHHHHHHH-----"))
aca2struct = np.array(list("--HHHHHHHHHH----HHHHHHH-----HHHHHHHHH------HHHHHHHHHHHHHHHHHHHHHHHHHHHH--EEEEE----HHHHHHHH----HHHHHHHHHHHHHHHH---EEEE--------"))
aca3struct = np.array(list("------------HHHHHHHHHH----HHHHHHHH---HHHHHHHHH------------HHHHHHHHHH--"))
aca4struct = np.array(list("--HHHHHHHHHHHH------HHHHHHHH-----HHHHHHHH---HHHHHHHHHHHHHHHHHHHHH--"))
aca5struct = np.array(list("--HHHHHHHH----HHHHHHH----HHHHHHHHH--EEEEE-----EEEE----------"))
aca6struct = np.array(list("--HHHHHHHH----HHHHHHHH---HHHHHHHH---------HHHHHHHHHHHHHHHH-------"))
aca7struct = np.array(list("-------------HHHHHHHHHH----HHHHHHHH--HHHHHHH------HHHHHHHHHHHHHH----"))
aca9struct = np.array(list("--EEEEE---EEEEE----HHHHHHHHHH----HHHHHHHH--HHHHHHHHHH--"))
aca10struct = np.array(list("-------HHHHHHHHHH----HHHHHHHH---HHHHHHHH-------HHHHHHHHHHHH------"))
aca11struct = np.array(list("---HHHHHHHHH----HHHHHH-----HHHHHHHH----E-----HHHHHHHHHHHHHH----"))
aca12struct = np.array(list("----HHHHHHHHH-----HHHHHHH----HHHHHHHH---HH-----HHHHHHHHHHHH----EHHHHHHHHHHHHHHHHHHHHH--EEEEE-"))
aca13struct = np.array(list("----HHHHHHHHHHHHH--HHHHHHHHHHH-HHHHHHHH--HHHHHHHHHHHHHHHH--"))

acaStructs = np.array([aca1struct,aca2struct,aca3struct,aca4struct,aca5struct,aca6struct,aca7struct,aca9struct,aca10struct,aca11struct,aca12struct,aca13struct])

from sklearn import preprocessing

# Encodes domain chars to integers, '-'=0, 'E'=1, 'H'=2
domains = ['-','E','H']
le = preprocessing.LabelEncoder()
le.fit(domains)

def getDomainTmat(seq):
  probs = np.zeros(shape=(len(domains),len(domains)))
  for i in range(len(seq)-1):
    probs[seq[i],seq[i+1]] += 1
  counts = [np.count_nonzero(seq[:-1]==n) for n in range(len(domains))]
  probs = (probs.T/counts).T
  probs[np.isnan(probs)] = 0
  for j in range(probs.shape[0]):
    if sum(probs[j,:]) == 0: probs[j,j] = 1 
  return probs

try:
    import hmmlearn
except ImportError:
    !pip install hmmlearn

from hmmlearn import hmm

acaHmms = []
for aca in acaStructs:
  a = le.transform(aca)
  acahmm = hmm.MultinomialHMM(n_components=len(domains),init_params="ste")
  acahmm.emissionprob_ = np.eye(3)
  acahmm.transmat_ = getDomainTmat(a)
  start_p = np.zeros(len(domains))
  start_p[a[0]] = 1
  acahmm.startprob_ = start_p
  acaHmms.append(acahmm)

print("Likelihood of aca1 give each acaHmm:")
likelihoods = np.zeros((acaStructs.shape[0], len(acaHmms)))
lengths = np.zeros((acaStructs.shape[0], len(acaHmms)))
a_ind = 0
h_ind = 0
for a in acaStructs:
  for h in acaHmms:
    likelihoods[a_ind, h_ind] = (np.exp(h.score(le.transform(a).reshape(-1,1))))
    lengths[a_ind, h_ind] = len(a)
    h_ind += 1
  h_ind = 0
  a_ind += 1
#random = '--HHHHHHHHHHHHHHH----------HHHHHHHHHHHHHHHHHH-----EEEEEHHHHHHHHHHHHH-----'
#random = '----EEEEEEE---HHHHHHHHHHHH----EEEEEE-----EEEEEEE---HHHHHHHHHHHHHHHH---EEEEEE-----HHHHHHH------'

random = '----H'
for h in acaHmms:
  print(np.exp(h.score(le.transform(list(random)).reshape(-1,1))))

0.8611111111111112**3*0.138888888888888

likelihoods

norm_likelihoods = np.zeros((acaStructs.shape[0], len(acaHmms)))
for n in range(12):
  norm_likelihoods[n] = likelihoods[n]/np.linalg.norm(likelihoods[n])

norm_likelihoods

def normalizeScore(lengths, scores):
  return np.log(scores)/lengths

from google.colab import drive
drive.mount('/content/drive')

# Assess all JNET results for pseudomonas
JNET_folder = "/content/drive/MyDrive/01 University/04 Senior/Computational Genomics/Project/Paeruginosa jpreds/Paeruginosa.faa_dir_output"
all_jpred = []
for filename in os.listdir(JNET_folder):
  if filename.endswith("jnet"):
    f = open(JNET_folder + '/' + filename, 'r')
    line1 = f.readline()
    line2 = f.readline()
    temp = list(line2[9:line2.index('\n')])
    count = temp.count(',')
    for c in range(count):
      temp.remove(',')
    all_jpred.append(temp)

likelihoods_sample = np.zeros((len(all_jpred), len(acaHmms)))
lengths_sample = np.zeros((len(all_jpred), len(acaHmms)))
j_ind = 0
h_ind = 0
for j in all_jpred:
  for h in acaHmms:
    likelihoods_sample[j_ind, h_ind] = (np.exp(h.score(le.transform(j).reshape(-1,1))))
    lengths_sample[j_ind, h_ind] = len(j)
    h_ind += 1
  h_ind = 0
  j_ind += 1

normalized_aca = normalizeScore(lengths, likelihoods)
normalized_sample = normalizeScore(lengths_sample, likelihoods_sample)
compare_aca = np.diag(normalized_aca)
comparison = np.zeros(lengths_sample.shape)

num_greater = np.zeros(normalized_sample.shape[0])
for x in range(normalized_sample.shape[0]):
  #for l in ghao:
  comparison[x,:] = normalized_sample[x,:] > compare_aca
  num_greater[x] = comparison[x,:].sum()

num_greater

plt.hist(num_greater, bins=12)

#cutoff: all 12 satisfied

#helper method from https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string
def find_nth(haystack, needle, n):
    start = haystack.find(needle)
    while start >= 0 and n > 1:
        start = haystack.find(needle, start+len(needle))
        n -= 1
    return start

def positionsOfInterest(num_greater, folder_dir):
  gene_pos = []
  curr_pos = 0
  for filename in os.listdir(folder_dir):
    if filename.endswith("jnet"):
      if num_greater[curr_pos] == 12:
        first = find_nth(filename, '|', 4)
        second = find_nth(filename, '|', 5)
        third = find_nth(filename, '_', 3)
        start = filename[first+1:second]
        end = filename[second+1:third]
        gene_pos.append((start,end))
      curr_pos += 1
  return gene_pos

positionsOfInterest(num_greater, JNET_folder)

tempPos = [('114611', '115045'),
 ('1094147', '1095337'),
 ('1098328', '1099128'),
 ('1100990', '1103077'),
 ('1103061', '1103927'),
 ('1108949', '1109866'),
 ('1109882', '1110868'),
 ('1119674', '1122217'),
 ('1124845', '1125465'),
 ('1125548', '1125865'),
 ('1150470', '1150721'),
 ('1150750', '1151415'),
 ('1151510', '1151908'),
 ('1152624', '1153538'),
 ('1161856', '1162977'),
 ('1160672', '1161595'),
 ('1174240', '1175559'),
 ('1175614', '1176375'),
 ('1176380', '1176982'),
 ('1177613', '1182697')]

import seaborn as sns
sns.color_palette("flare", as_cmap=True)
ax = sns.heatmap(comparison, cmap = "flare")
plt.figure(figsize=(20,15))
plt.show()



import seaborn as sns
sns.color_palette("flare", as_cmap=True)
ax = sns.heatmap(norm_likelihoods, cmap = "flare")
plt.figure(figsize=(20,15))
plt.show()

# Test to make sure that the best model for each aca is the model built from that sequence

ref_probs = [np.exp(acaHmms[i].score(le.transform(acaStructs[i]).reshape(-1,1))) for i in range(len(acaStructs))]

max_probs = []
for a in acaStructs:
  prs = []
  for h in acaHmms:
    prs.append(np.exp(h.score(le.transform(a).reshape(-1,1))))
  max_probs.append(np.max(prs))

print(ref_probs==max_probs)

"""Below: hardcoded transition matrix for non-aca-acr region based on avg domain lengths"""

# Domain transition matrix for s_bef and s_aft, adapted from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1479840/
# -, E, H
# Average alpha helix length = 10 http://www.cryst.bbk.ac.uk/PPS2/course/section8/ss-960531_6.html
# Average beta sheet length = 6 http://www.cryst.bbk.ac.uk/PPS2/course/section8/ss-960531_10.html
# Assume residue distribution of 1/3 helices, 1/3 sheets, 1/3 -
def getNonacaTmat(seq):
  seq_tmat = np.array([[0,0.686,0.314],
                      [0.971,0,0.029],
                      [0.969,0.031,0]])
  seq_tmat = seq_tmat.flatten() / 3

  # Calculate number of non-domain segments (assumes no helix<->sheet transitions)
  num_helix = len(seq)/3 / 10
  num_sheet = len(seq)/3 / 6
  num_seg = num_sheet+num_helix + 1 # One non-domain seg follows each domain, + 1 for beginning
  avg_seg_len = len(seq)/3 / num_seg

  # Modify transition probs to reflect avg lengths
  seq_tmat[0] = (1-1/avg_seg_len)/3
  seq_tmat[1:3] = seq_tmat[1:3]*1/avg_seg_len
  seq_tmat[4] = (1-1/6)/3
  seq_tmat[3] = seq_tmat[3]*1/6
  seq_tmat[5] = seq_tmat[5]*1/6
  seq_tmat[-1] = (1-1/10)/3
  seq_tmat[-3:-1] = seq_tmat[-3:-1]*1/10

  return seq_tmat

print(sum(getNonacaTmat(np.ones(10000))))



"""Below: secondary structure hmms for acrs"""

#acrProtDF = pd.read_csv("/content/drive/MyDrive/Fourth Year/Second Sem/Cg/Project/acrproteins.csv",header=0)
acrProtDF = pd.read_csv("/content/drive/MyDrive/01 University/04 Senior/Computational Genomics/Project/acrproteins.csv",header=0)
verifiedAcrdf = acrProtDF.loc[acrProtDF['classify'].isin(["Verified"])]
acrStructsdf = pd.read_csv("/content/drive/MyDrive/01 University/04 Senior/Computational Genomics/Project/acrSecondaryStructs.csv",names=["acr_id","struct_seq"],index_col=0)

print(np.shape(acrProtDF))

"""Build secondary struct hmm for each type of acr"""

# get list of unique types (since some have two w/ slash)
typeset = set(verifiedAcrdf['Anti_type'])
newset = typeset.copy()
for t in typeset:
  if '/' in t or ',' in t:
    newset.remove(t)
typeset = newset

acrHmms = {}
for t in typeset:
  # get only acrs of a given type (regex expression includes those with multiple types)
  typedf = verifiedAcrdf.loc[verifiedAcrdf['Anti_type'].str.match(fr'(\w/)*{t}(/\w)*$')]

  # learn transition matrix for secondary structures from sequences
  t_mats = []
  for i in typedf.index:
    id = typedf.loc[i,'anti_CRISPR_id']
    if np.any(acrStructsdf.index.str.contains(id,regex=False)):
      matchdf = acrStructsdf[acrStructsdf.index.str.contains(id,regex=False)]
      t_mats.append(getDomainTmat(le.transform(list(matchdf.iloc[0,0]))))
  avgTmat = np.mean( np.array(t_mats), axis=0 )
  
  # build hmm
  acrhmm = hmm.MultinomialHMM(n_components=len(domains),init_params="ste")
  acrhmm.emissionprob_ = np.eye(3)
  acrhmm.transmat_ = avgTmat
  start_p = np.zeros(len(domains))
  start_p[0] = 1
  acrhmm.startprob_ = start_p
  acrHmms[t] = acrhmm

acrStructsdf.head()

# builld 2nd struct hmm for all acrs
acrhmm = hmm.MultinomialHMM(n_components=len(domains),init_params="ste")
acrhmm.emissionprob_ = np.eye(3)
print(list(np.sum(acrStructsdf.to_numpy()[:,0].flatten())))
acrhmm.transmat_ = getDomainTmat(le.transform(list(np.sum(acrStructsdf.to_numpy()[:,0].flatten()))))
start_p = np.zeros(len(domains))
start_p[0] = 1
acrhmm.startprob_ = start_p

print(acrhmm.score(acrStructsdf.to_numpy))



# test score
print(acrHmms.keys())
acrHmms['I-E'].score(le.transform(list(acrStructsdf.iloc[0,0])).reshape(-1,1))

"""#Backtracking to find acr

## load acrX genes
"""

acrProtDF = pd.read_csv("/content/drive/MyDrive/Fourth Year/Second Sem/Cg/Project/acrproteins.csv",header=0)
acrProtDF

"""##AcrX structural characterization """

acrseqdf = acrProtDF["Seq"]
#acrc = toColors(toProperties(acrseqdf.loc[482]))
acrseqdf
#plt.scatter(np.linspace(0, 10, num = len(acrc)), [1]*len(acrc), c=acrc, s=20)

for i in range(acrseqdf.shape[0]):
  try:
    ACRc = toColors(toProperties(acrseqdf.loc[i]))
    plt.scatter(np.linspace(0, 1, num = len(ACRc)), [i]*len(ACRc), c=ACRc, s=8)
  except:
    print("Color error at ", i)

  

#plt.scatter(np.linspace(0, 10, num = len(ACA2decoded)), [2]*len(ACA2decoded), c=ACA2decoded,s=20)

#calculate how similar two aca genes are on the basis of transition homology 
def similarityScore(tm1, tm2):
  delta = tm1-tm2
  score = np.sum(np.abs(delta))
  if score == 0:
    return 0
  else:
    return 1/score
    
def transitionHomology(tmList):
  tmhMat = np.eye(len(tmList))
  for i in range(len(tmList)):
    for j in range(len(tmList)):
      tmhMat[i, j] = similarityScore(tmList[i], tmList[j])
  
  return tmhMat

adjList(toProperties(acrseqdf.iloc[0]))

tms = []
for i in range(acrseqdf.shape[0]):
  acrX  = acrseqdf.loc[i]
  tms.append(adj_trans(adjList(toProperties(acrX))))

tms = np.asarray(tms)
print(tms[600])
np.shape(tms)

meanTM = np.mean(tms, axis = 0)
meanTM

Emat = emat

start_probs = []

thms = transitionHomology(tms)

print(thms)

import seaborn as sns
sns.color_palette("flare", as_cmap=True)
ax = sns.heatmap(thms, cmap = "flare")
plt.figure(figsize=(20,15))
plt.show()

small = thms[500:1300,500:1300]

sns.color_palette("flare", as_cmap=True)
ax = sns.heatmap(small, cmap = "flare")
plt.figure(figsize=(20,15))
plt.show()

"""
#Learn an HMM for Acr Peptides


*   Alphabet: amino acids
*   States: chem_states
"""

from hmmlearn import hmm

def toNums(lis):
  n =[]
  for x in lis:
   n.append(ord(x))
  return n

#make a matrix of seqs
acrs = []
acrs2 = []
for i in range(acrseqdf.shape[0]):
  #print([list(acrseqdf[i])])
  acrs.append([toNums(list(acrseqdf[i]))])
  acrs2.append(toNums(list(acrseqdf[i])))

lengths = [len(x) for x in acrs]

plt.hist(lengths, bins = 20)
plt.show()

acr_general_hmm = hmm.MultinomialHMM(n_components=6,init_params="ste")
acr_general_hmm.emissionprob_ = np.random.rand(6,20)
acr_general_hmm.transmat_ = np.random.rand(6,6)
start_p = [1,0,0,0,0,0]

acr_general_hmm.startprob_ = start_p

import sklearn
from sklearn import preprocessing

# concatenate acr proteins to one X for hmm.fit
pep_input = np.array(list(np.sum(acrseqdf.to_numpy().flatten())))
le_pep = preprocessing.LabelEncoder()
le_pep.fit_transform(pep_input)
acr_general_hmm.fit(le_pep.fit_transform(pep_input).reshape(-1,1))

import pickle
with open("acr_general_hmm.pkl", "wb") as file: pickle.dump(acr_general_hmm, file)

with open("acr_general_hmm.pkl", "rb") as file: pickle.load(file)

peps = pd.read_csv("/content/drive/MyDrive/01 University/04 Senior/Computational Genomics/Project/peps.csv")

candidate_seqs = peps.seq_aa
candidate_seqs

#test_input = np.array(list(np.sum(candidate_seqs.to_numpy().flatten())))

#print(test_input)
scores = []
for i in range(candidate_seqs.shape[0]):
  test_input = list(candidate_seqs[i])
  le_pep_test = preprocessing.LabelEncoder()
  le_pep_test.fit_transform(test_input)
  scores.append(acr_general_hmm.score(le_pep_test.fit_transform(test_input).reshape(-1,1)))

peps.insert(loc = 2, column='scores', value=scores)

peps

mask = (peps['seq_aa'].str.len() < 270)
pep_cands = peps.loc[mask]

pep_cands.hist('scores')

mask2 = (pep_cands['scores'] > -180)

pep_cands = pep_cands[mask2]

pep_cands

def get_cand_coords(candsFile):
  coords = []
  for txt in candsFile.seq_name:
        #txt = candsFile.loc[i, 'seq_name']
        a = [int(s) for s in re.findall(r'\b\d+\b', txt)]
        coords.append(list(a))
  return coords

locations = np.asarray(get_cand_coords(pep_cands))
locations

tempLoc = [[  65541,   65678],
       [ 352227,  352316],
       [ 683398,  683508],
       [ 790617,  790709],
       [ 794268,  794369],
       [ 863669,  863785],
       [1116133, 1116216],
       [1340636, 1340737],
       [1398450, 1398557],
       [1489396, 1489494],
       [1775945, 1776034],
       [1878447, 1878548],
       [1948389, 1948505],
       [2126021, 2126107],
       [2149309, 2149389],
       [2761724, 2761831],
       [3108663, 3108752],
       [3125429, 3125524],
       [3131047, 3131142],
       [3137667, 3137774],
       [3147641, 3147733],
       [3200320, 3200418],
       [3475171, 3475257],
       [3534629, 3534724],
       [3544886, 3544993],
       [3547109, 3547210],
       [3581949, 3582080],
       [3682840, 3682923],
       [3705370, 3705483],
       [3858434, 3858547],
       [4035606, 4035758],
       [4168864, 4168953],
       [4295564, 4295680],
       [4332470, 4332610],
       [4756979, 4757095],
       [5303892, 5303978],
       [5386132, 5386248],
       [5456318, 5456410],
       [5885170, 5885301],
       [6085227, 6085337],
       [6151446, 6151526]]

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection

fig, ax = plt.subplots()
ax.plot([0, 7000000], [1, 1], color='dimgrey', linewidth = 10)
ax.plot([0, 7000000], [2, 2], color='dimgrey', linewidth = 10)
ax.set_xticklabels([])
#Y = 1: ACA
#Y = 2: ACR

for x in range(len(tempLoc)):
  print(tempLoc[x][0])
  ax.plot([tempLoc[x][0]-10000, tempLoc[x][1]+10000], [2, 2], color='red', linewidth = 10)
#for x in range(len(tempLoc)):
#  ax.plot([tempLoc[x][0], tempLoc[x][1]], [2, 2], color='red')

for x in range(len(tempPos)):
  ax.plot([int(tempPos[x][0]) - 10000, int(tempPos[x][1]) +10000], [1, 1], color='blue', linewidth = 10)

plt.ylim([0, 3])
plt.xlim([1000000, 2000000])
plt.show

tempPos

tempLoc